{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For neutral network in tensorflow, we use:\n",
    "- Tensor to represent data\n",
    "- Computation graphs to build neutral network\n",
    "- Session to execute computation graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor: Basic unit of data\n",
    "- Scalars (0D tensors)\n",
    "- Vector (1D tensors)\n",
    "- Matrix (2D tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalars (0D tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.50159764, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "random_float = tf.random.uniform(shape = ())             # Declare a random float (scalar).\n",
    "print(random_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(5.0)                                     # Declare a float (scalar).\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector (1D tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([0 0], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "zero_vector = tf.zeros(shape = (2))                      # Declare a zero vector with two elements, default type: float.\n",
    "print(zero_vector)\n",
    "zero_vector1 = tf.zeros(shape = (2), dtype = tf.int32)   # Declare two 2*2 constant matrices A and B, change float to int\n",
    "print(zero_vector1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix (2D tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[5. 6.]\n",
      " [7. 8.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant([[1., 2.], [3., 4.]])                    # Declare a 2×2 constant matrix\n",
    "print(A)\n",
    "B = tf.constant([[5., 6.], [7., 8.]])\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes of tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor have 3 important attributes: shape, data type and value. \n",
    "\n",
    "You can use the shape, data type attribute and the numpy() method to fetch them. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "<dtype: 'float32'>\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(A.shape)      \n",
    "print(A.dtype)      \n",
    "print(A.numpy())     #  numpy() method of a tensor is to return a NumPy array whose value equals the value of the tensor.\n",
    "print(A.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_images.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(train_images.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have here is a 3D tensor of 8-bit integers. More precisely, it is an array of 60,000 matrices of 28x28 integers. \n",
    "\n",
    "Each such matrix is a grayscale image, with coefficients between 0 and 255.\n",
    "\n",
    "Let’s display the 4th digit in this 3D tensor, using the library Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[4]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap = plt.cm.binary)        # cmap: color map, e.g.: cmap = plt.cm.RdGy\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[10:100, :, :]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation Graphs\n",
    "Build the process of computation and input it inot y node, but without results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./img/1_computation_graph.png\" width= 600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 6.  8.]\n",
      " [10. 12.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[19. 22.]\n",
      " [43. 50.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant([[1., 2.], [3., 4.]])                   # Declare a 2×2 constant matrix\n",
    "B = tf.constant([[5., 6.], [7., 8.]])\n",
    "\n",
    "C = tf.add(A, B)                                        # Compute the elementwise sum of A and B.\n",
    "print(C)\n",
    "\n",
    "D = tf.matmul(A, B)                                     # Compute the multiplication of A and B.\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[11.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1.0, 2.0]])                           # Build a graph.\n",
    "w = tf.constant([[3.0], [4.0]])\n",
    "y = tf.matmul(x, w)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session\n",
    "Execute the operation of the node in computation graphs (y node)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./img/2_session.png\" width= 600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:  #\n",
    "    x = tf.constant([[1.0, 2.0]])\n",
    "    w = tf.constant([[3.0], [4.0]])\n",
    "    y = tf.matmul(x, w)\n",
    "    print(sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-world examples of data tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vector data: 2D tensors of shape (samples, features).\n",
    "- Timeseries data or sequence data: 3D tensors of shape (samples, timesteps, features).\n",
    "- Images: 4D tensors of shape (samples, width, height, channels) or (samples, channels, width, height).\n",
    "- Video: 5D tensors of shape (samples, frames, width, height, channels) or (samples, frames, channels, width, height)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector data\n",
    "\n",
    "A batch of data will be encoded as a 2D tensor (i.e. an array of vectors),\n",
    "where the first axis is the <font color=red>**\"samples axis\"**</font> and the second axis is the <font color=red>**\"features axis\"**</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For example,** an actuarial dataset of people, where we consider for each person their age, zipcode, and income. Each person can be characterized as a vector of 3 values, and thus an entire dataset of 100,000 people can be stored in a 2D tensor of shape (100000, 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeseries data or sequence data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample can be encoded as a sequence of vectors (a 2D tensor), and thus a batch of data will be encoded as a 3D tensor.\n",
    "\n",
    "**The time axis will always be the second axis (axis of index 1), by convention.** Let’s have a look at a few examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset of stock prices. Every minute, we store the current price of the stock, the\n",
    "highest price in the past minute and the lowest price in the past minute. Thus every\n",
    "minute is encoded as a 3D vector, an entire day of trading is encoded as a 2D tensor of\n",
    "shape (390, 3) (there are 390 minutes in a trading day), and 250 days worth of data can\n",
    "be stored in a 3D tensor of shape (250, 390, 3). Here, each sample would be one day\n",
    "worth of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./img/3_series.png\" width = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A batch of 128 grayscale images of size 256x256 could thus be stored in a tensor of shape \n",
    "(128, 256, 256, 1), and a batch of 128 color images could be stored in a tensor of shape (128, 256, 256, 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./img/4_image.png\" width = 350>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Google, places the color depth axis at the end, as we just saw: (samples, width, height, **color_depth**).\n",
    "\n",
    "- Theano places the color depth axis right after the batch axis: (samples, **color_depth**, width, height)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video data needs 5D tensors. A video can be understood as a sequence of frames, each frame being a color image.\n",
    "Since each frame can be stored in a 3D tensor (width, height, color_depth), then a sequence of frames can be \n",
    "stored in 4D tensor (frames, width, height, color_depth), and thus a batch of different videos can be stored \n",
    "in a 5D tensor of shape (samples, frames, width, height, color_depth).\n",
    "\n",
    "For instance, a 60-second, 256x144 YouTube video clip sampled at 4 frames per second would have 240 frames. \n",
    "A batch of 4 such video clips would be stored in a tensor of shape (4, 240, 256, 144, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
